# etl_pipeline_using_airflow
Building an ETL using airflow which reads data from API every minute and load it into datalake.
